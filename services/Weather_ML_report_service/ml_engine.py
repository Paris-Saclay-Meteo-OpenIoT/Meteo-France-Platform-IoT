import pandas as pd
import numpy as np
import logging
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from datetime import datetime, timedelta, timezone
from zoneinfo import ZoneInfo

logger = logging.getLogger(__name__)
PARIS_TZ = ZoneInfo('Europe/Paris')

def run_ml_pipeline(df, station_mapping=None, target_stations=None):
    """
    Ex√©cute le pipeline ML pour g√©n√©rer des pr√©dictions m√©t√©orologiques
    
    Args:
        df: DataFrame avec les donn√©es m√©t√©orologiques historiques
        station_mapping: Dictionnaire nom_usuel -> station_id (NUM_POSTE)
        target_stations: Liste des stations √† traiter (None = toutes)
    
    Returns:
        DataFrame avec les pr√©dictions (station, forecast_time, lat, lon, t_pred, ff_pred, rr1_pred)
    """
    logger.info("üîÆ INITIALISATION DU MOTEUR DE PR√âDICTION ML")
    logger.info(f"   üìä Donn√©es d'entr√©e: {len(df)} enregistrements")
    
    df['date'] = pd.to_datetime(df['date'])
    
    # Ne supprimer que les lignes o√π les colonnes ESSENTIELLES sont nulles
    # (pas dd, n, vis etc. qui peuvent √™tre absentes dans les donn√©es API)
    essential_cols = ['nom_usuel', 'date', 't', 'u', 'ff', 'rr1']
    existing_essential = [c for c in essential_cols if c in df.columns]
    df = df.dropna(subset=existing_essential).copy()
    
    if df.empty:
        logger.warning("‚ö†Ô∏è  DataFrame VIDE apr√®s nettoyage, impossible d'ex√©cuter le ML")
        return pd.DataFrame()
    
    logger.info(f"   ‚úì Apr√®s nettoyage: {len(df)} enregistrements valides")
    
    required_cols = ['nom_usuel', 't', 'u', 'ff', 'rr1']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        logger.error(f"   ‚ùå Colonnes manquantes: {missing_cols}")
        return pd.DataFrame()
    
    logger.info("   ‚úì Toutes les colonnes requises pr√©sentes")
    
    # Filtrer par stations cibles si sp√©cifi√©es
    if target_stations:
        logger.info(f"   üéØ Filtrage pour stations cibles: {target_stations}")
        df = df[df['nom_usuel'].isin(target_stations)]
        logger.info(f"   ‚úì Filtr√© pour stations cibles: {len(df)} enregistrements")
        if df.empty:
            logger.warning("   ‚ö†Ô∏è  Aucun enregistrement trouv√© pour les stations cibles")
            return pd.DataFrame()
    
    # D√©terminer la p√©riode historique √† utiliser (5 ans si possible, sinon 1 an, sinon tout)
    now = datetime.now()
    min_date_5y = now - timedelta(days=5*365)
    min_date_1y = now - timedelta(days=365)
    if df['date'].min() <= min_date_5y:
        logger.info("‚è≥ Utilisation de l'historique sur 5 ans pour les pr√©dictions")
        df = df[df['date'] >= min_date_5y].copy()
    elif df['date'].min() <= min_date_1y:
        logger.info("‚è≥ Utilisation de l'historique sur 1 an (pas assez de donn√©es pour 5 ans)")
        df = df[df['date'] >= min_date_1y].copy()
    else:
        logger.info("‚è≥ Utilisation de tout l'historique disponible (moins d'1 an de donn√©es)")
    
    le = LabelEncoder()
    df['SID'] = le.fit_transform(df['nom_usuel'])
    
    # Si lat/lon manquent, les ajouter avec des valeurs par d√©faut
    if 'lat' not in df.columns:
        df['lat'] = 0.0
    if 'lon' not in df.columns:
        df['lon'] = 0.0
    
    coords_map = df[['nom_usuel', 'lat', 'lon']].drop_duplicates().set_index('nom_usuel')
    features = ['SID', 't', 'u', 'ff']
    stations = df['nom_usuel'].unique()
    
    logger.info(f"\nüéØ STATIONS √Ä TRAITER: {len(stations)}")
    for i, st in enumerate(stations, 1):
        logger.info(f"   {i}. {st}")
    
    # Calcul de la base de pr√©diction en heure fran√ßaise (Europe/Paris)
    # Le container tourne en UTC, mais les pr√©dictions doivent correspondre au jour √† venir en heure locale
    # - Si ex√©cution autour de minuit (0h-1h CET) : pr√©dictions pour le jour courant (00:00 ‚Üí 23:00 CET)
    # - Si ex√©cution en journ√©e (startup) : pr√©dictions pour le lendemain (00:00 ‚Üí 23:00 CET)
    now_local = datetime.now(PARIS_TZ)
    if now_local.hour < 2:
        # Ex√©cution planifi√©e autour de minuit ‚Üí pr√©dire pour le jour courant (heure locale)
        forecast_base_local = now_local.replace(hour=0, minute=0, second=0, microsecond=0)
    else:
        # Ex√©cution en journ√©e (startup) ‚Üí pr√©dire pour demain (heure locale)
        forecast_base_local = (now_local + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
    
    # Convertir en UTC na√Øf pour stockage PostgreSQL (TIMESTAMP WITHOUT TIMEZONE)
    forecast_base = forecast_base_local.astimezone(timezone.utc).replace(tzinfo=None)
    
    all_rows = []
    target_day = forecast_base_local.strftime('%A %d/%m/%Y')
    
    logger.info(f"\n‚è∞ Ex√©cution √†: {now_local.strftime('%H:%M')} (heure locale Paris)")
    logger.info(f"üìÖ Jour cible des pr√©dictions: {target_day}")
    logger.info(f"üìà Plage: {forecast_base_local.strftime('%d/%m %H:%M')} ‚Üí {(forecast_base_local + timedelta(hours=23)).strftime('%d/%m %H:%M')} CET (stock√© en UTC: {forecast_base.strftime('%H:%M')} ‚Üí {(forecast_base + timedelta(hours=23)).strftime('%H:%M')})")
    
    # Entrainer les mod√®les et g√©n√©rer les pr√©dictions
    for target_col in ['t', 'ff', 'rr1']:
        logger.info(f"\nü§ñ Entra√Ænement du mod√®le pour: {target_col.upper()}")
        
        y = np.array([df[target_col].shift(-i).values for i in range(1, 25)]).T
        valid_idx = ~np.isnan(y).any(axis=1)
        X_train = df[valid_idx][features]
        y_train = y[valid_idx]
        
        logger.info(f"   üìö Ensemble d'entra√Ænement: {len(X_train)} √©chantillons")
        
        try:
            model = RandomForestRegressor(n_estimators=50, n_jobs=-1, random_state=42)
            model.fit(X_train, y_train)
            logger.info("   ‚úÖ Mod√®le entra√Æn√© avec succ√®s (RandomForest 50 estimators)")
            
            # G√©n√©rer les pr√©dictions pour chaque station
            for station in stations:
                last_data = df[df['nom_usuel'] == station].sort_values('date').iloc[-1:]
                if last_data.empty:
                    continue
                    
                preds = model.predict(last_data[features])[0]
                # station_mapping mappe nom_usuel -> station_id (= NUM_POSTE pour les donn√©es r√©elles)
                station_id = station_mapping.get(station, station) if station_mapping else station
                
                for i, val in enumerate(preds):
                    forecast_time = forecast_base + timedelta(hours=i)  # 00:00 ‚Üí 23:00 du jour cible
                    found = False
                    for row in all_rows:
                        if row['station'] == station_id and row['forecast_time'] == forecast_time:
                            row[f'{target_col.lower()}_pred'] = round(val, 2)
                            found = True
                            break
                    if not found:
                        all_rows.append({
                            'station': station_id,
                            'forecast_time': forecast_time,
                            'lat': coords_map.loc[station, 'lat'], 
                            'lon': coords_map.loc[station, 'lon'], 
                            f'{target_col.lower()}_pred': round(val, 2)
                        })
        except Exception as e:
            logger.error(f"   ‚ùå Erreur lors de l'entra√Ænement du mod√®le {target_col}: {e}", exc_info=True)
    
    result_df = pd.DataFrame(all_rows)
    
    if result_df.empty:
        logger.warning("‚ö†Ô∏è  Aucune pr√©diction g√©n√©r√©e!")
        logger.info("\n‚úÖ Pipeline ML COMPL√âT√â (sans pr√©dictions)")
        return result_df
    
    logger.info(f"\nüìä R√âSUM√â DES PR√âDICTIONS G√âN√âR√âES")
    logger.info(f"   ‚úì Nombre total de pr√©dictions: {len(result_df)}")
    logger.info(f"   ‚úì Stations couvertes: {result_df['station'].nunique()}")
    logger.info(f"   ‚úì Horizons de pr√©diction par station: {len(result_df) // max(1, result_df['station'].nunique())}")
    
    if not result_df.empty:
        logger.info("\n   üìå √âchantillon de pr√©dictions:")
        for _, row in result_df.head(3).iterrows():
            logger.info(f"      Station {row['station']}: T={row.get('t_pred', 'N/A')}¬∞C, FF={row.get('ff_pred', 'N/A')}m/s, RR1={row.get('rr1_pred', 'N/A')}mm")
    
    logger.info("\n‚úÖ Pipeline ML COMPL√âT√â AVEC SUCC√àS")
    return result_df