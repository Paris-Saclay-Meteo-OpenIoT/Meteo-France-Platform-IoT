import pandas as pd
import logging
from sqlalchemy import create_engine, text
from config import DB_URI

logger = logging.getLogger(__name__)
engine = create_engine(DB_URI)

def get_weather_data():
    """R√©cup√®re toutes les donn√©es m√©t√©orologiques depuis PostgreSQL"""
    logger.info("üîç Requ√™te des donn√©es m√©t√©orologiques...")
    try:
        query = "SELECT * FROM weather_data ORDER BY date DESC"
        with engine.connect() as conn:
            df = pd.read_sql(text(query), conn)
            df.columns = [c.lower() for c in df.columns]
            logger.info(f"   ‚úì {len(df)} enregistrements r√©cup√©r√©s")
            if not df.empty:
                logger.info(f"   ‚úì Colonnes disponibles: {', '.join(df.columns)}")
                logger.info(f"   ‚úì Stations uniques: {df['nom_usuel'].nunique()}")
            return df
    except Exception as e:
        logger.error(f"   ‚ùå Erreur lors de la r√©cup√©ration des donn√©es: {e}", exc_info=True)
        return pd.DataFrame()

def get_station_mapping():
    """Cr√©er un mapping entre nom_usuel (du ML) et station_id (de MongoDB)"""
    logger.info("üîó Cr√©ation du mapping stations...")
    try:
        query = """
            SELECT DISTINCT nom_usuel, station_id FROM weather_data 
            WHERE nom_usuel IS NOT NULL AND station_id IS NOT NULL
            ORDER BY nom_usuel
        """
        with engine.connect() as conn:
            result = pd.read_sql(text(query), conn)
            if result.empty:
                logger.warning("   ‚ö†Ô∏è  Aucune station trouv√©e pour le mapping")
                return {}
            mapping = dict(zip(result['nom_usuel'], result['station_id']))
            logger.info(f"   ‚úì Mapping cr√©√© avec {len(mapping)} stations:")
            for nom, sid in sorted(mapping.items()):
                logger.info(f"      - {nom:15s} ‚Üí {sid}")
            return mapping
    except Exception as e:
        logger.error(f"   ‚ùå Erreur r√©cup√©ration mapping stations: {e}", exc_info=True)
        return {}

def save_predictions(df):
    """Sauvegarde les pr√©dictions dans PostgreSQL avec upsert"""
    logger.info("üíæ SAUVEGARDE DES PR√âDICTIONS DANS POSTGRESQL")
    
    if df.empty:
        logger.warning("   ‚ö†Ô∏è  Aucune pr√©diction √† sauvegarder")
        return
    
    logger.info(f"   üìä Nombre de pr√©dictions: {len(df)}")
    logger.info(f"   üèòÔ∏è  Nombre de stations: {df['station'].nunique()}")
    logger.info(f"   üìÖ Plage temporelle: {df['forecast_time'].min()} √† {df['forecast_time'].max()}")
    
    try:
        with engine.connect() as conn:
            # Cr√©er la table si elle n'existe pas
            logger.info("   üìã V√©rification/cr√©ation de la table forecast_results...")
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS forecast_results (
                    id SERIAL,
                    station VARCHAR(50),
                    station_id VARCHAR(50),
                    forecast_time TIMESTAMP,
                    forecast_date DATE,
                    lat FLOAT,
                    lon FLOAT,
                    t_pred FLOAT,
                    ff_pred FLOAT,
                    rr1_pred FLOAT,
                    u_pred FLOAT DEFAULT NULL,
                    model_version VARCHAR(50) DEFAULT NULL,
                    created_at TIMESTAMP DEFAULT NOW(),
                    UNIQUE(station, forecast_time)
                );
            """))
            
            # Sauvegarder les pr√©dictions
            logger.info("   ‚è≥ Insertion des pr√©dictions...")
            
            # Convertir les types numpy/Series en types Python natifs pour psycopg2
            df_clean = df.copy()
            for col in ['lat', 'lon', 't_pred', 'ff_pred', 'rr1_pred', 'u_pred']:
                if col in df_clean.columns:
                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').astype(float)
            if 'station' in df_clean.columns:
                df_clean['station'] = df_clean['station'].astype(str)
            
            # Ajouter station_id (= station) et forecast_date si absents
            if 'station_id' not in df_clean.columns and 'station' in df_clean.columns:
                df_clean['station_id'] = df_clean['station']
            if 'forecast_date' not in df_clean.columns and 'forecast_time' in df_clean.columns:
                df_clean['forecast_date'] = pd.to_datetime(df_clean['forecast_time']).dt.date
            
            df_clean.to_sql('temp_forecast', conn, if_exists='replace', index=False)
            
            # Upsert (insert or update) - construire dynamiquement bas√© sur les colonnes nettoy√©es
            available_cols = df_clean.columns.tolist()
            columns_str = ', '.join(available_cols)
            select_str = ', '.join(available_cols)
            update_str = ', '.join([f"{col} = EXCLUDED.{col}" for col in available_cols if col not in ['station', 'forecast_time']])
            
            upsert_query = text(f"""
                INSERT INTO forecast_results ({columns_str})
                SELECT {select_str}
                FROM temp_forecast
                ON CONFLICT (station, forecast_time) 
                DO UPDATE SET {update_str};
            """)
            conn.execute(upsert_query)
            conn.execute(text("DROP TABLE temp_forecast;"))
            conn.commit()
            
            logger.info(f"   ‚úÖ {len(df)} pr√©dictions sauvegard√©es avec succ√®s")
            
            # V√©rifier le r√©sultat
            logger.info("   üìà V√©rification des donn√©es sauvegard√©es...")
            verify_query = text("SELECT COUNT(*) as count, COUNT(DISTINCT station) as stations FROM forecast_results")
            result = conn.execute(verify_query).fetchone()
            logger.info(f"      Total pr√©dictions en BD: {result[0]}")
            logger.info(f"      Nombre de stations: {result[1]}")
            
    except Exception as e:
        logger.error(f"   ‚ùå Erreur lors de la sauvegarde: {e}", exc_info=True)
        raise